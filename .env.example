# Open Speech — Configuration
# Copy to .env and edit. All values shown are defaults.
# Works with both docker-compose and `docker run --env-file .env`

# ── Device & Model ──────────────────────────────────────────────
# STT_DEVICE=cuda                 # cuda | cpu
# STT_COMPUTE_TYPE=float16        # float16 | int8 | int8_float16
# STT_DEFAULT_MODEL=deepdml/faster-whisper-large-v3-turbo-ct2
# STT_PRELOAD_MODELS=             # Comma-separated models to load on startup
# STT_MODEL_DIR=                  # Custom model cache dir (default: HuggingFace cache)

# ── Model Lifecycle ──────────────────────────────────────────────
# STT_MODEL_TTL=300               # Seconds idle before auto-unload (0 = never). Default model exempt.
# STT_MAX_LOADED_MODELS=0         # Max models in memory (0 = unlimited). LRU eviction, default exempt.

# ── Server ──────────────────────────────────────────────────────
# STT_HOST=0.0.0.0
# STT_PORT=8100

# ── Streaming ───────────────────────────────────────────────────
# STT_STREAM_CHUNK_MS=2000        # Audio chunk size in ms
# STT_STREAM_VAD_THRESHOLD=0.5    # VAD confidence threshold (0.0-1.0)
# STT_STREAM_ENDPOINTING_MS=300   # Silence before finalizing utterance
# STT_STREAM_MAX_CONNECTIONS=10   # Max concurrent WebSocket sessions

# ── Security ────────────────────────────────────────────────────
# STT_API_KEY=                    # Set to require Bearer auth (empty = disabled)
# STT_RATE_LIMIT=0                # Requests/min per IP (0 = disabled)
# STT_RATE_LIMIT_BURST=0          # Burst allowance (0 = same as rate_limit)
# STT_MAX_UPLOAD_MB=100           # Max upload file size
# STT_CORS_ORIGINS=*              # Comma-separated allowed origins
# STT_TRUST_PROXY=false           # Trust X-Forwarded-For (set true behind reverse proxy)
