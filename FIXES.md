# Open Speech â€” Fixes & Feature Requests

Quick intake for bugs, fixes, and feature ideas. Will triages, Forge builds.

For bigger items, open a [GitHub Issue](https://github.com/will-assistant/open-speech/issues).

## Status Key
- ğŸ”´ Open
- ğŸŸ¡ In Progress (dispatched to Forge)
- ğŸŸ¢ Done (commit linked)

---

## Bugs

| # | Description | Status | Commit |
|---|-------------|--------|--------|
| B32 | **qwen3-tts still fails after B26 fix** â€” `qwen-tts` pulls `torchaudio` from PyPI (CPU-only) which conflicts with CUDA torch in GPU image. Fix: pre-install torchaudio from PyTorch CUDA index before qwen-tts install, both in Dockerfile bake step and runtime UI install path. Also added qwen deps to `[all]` extra. | ğŸŸ¢ | 1bdd3d4 |
| B1 | Mic transcription captures nothing (WebSocket/format issue) | ğŸŸ¢ | 9070140 |
| B2 | Piper backend passes `length_scale` kwarg rejected by current piper-tts API â†’ synthesis fails with "# channels not specified" | ğŸŸ¢ | e19eea3 |
| B3 | WebSocket library missing â€” uvicorn starts without `websockets`/`wsproto`, mic streaming broken. Fix: add `websockets` to Dockerfile deps + pyproject extras. Log: `WARNING: No supported WebSocket library detected` | ğŸŸ¢ | â€” |
| B4 | `/v1/audio/stream` endpoint returns 404 (GET with query params). Likely route not registered or WebSocket upgrade fails silently before route match. Related to B3. | ğŸŸ¢ | 8bfe6f9 |
| B5 | Piper `synthesize()` ignores requested model â€” always uses first loaded. `voice` param = model_id but code just grabs first key from `self._loaded` dict (line 187). Should match `voice` to loaded model key. | ğŸŸ¢ | c2f47b0 |
| B6 | Provider install (`/api/providers/install`) installs packages to `~/.local` instead of system site-packages. Server can't import them. Cause: `pip install --user` default when not root. Fix: use `pip install --target` or `sys.executable -m pip install` pointing at the right site-packages dir. **Also:** when kokoro is installed, must run `python -m spacy download en_core_web_sm` (misaki phonemizer dep) â€” baked into CPU image but not GPU image. | ğŸŸ¢ | ee712e4 |
| B7 | Inconsistent API error envelope â€” some endpoints return `{"error":"..."}` others `{"detail":"..."}` (FastAPI HTTPException default). Standardize all to `{"error":{"message":"..."}}`. See PROJECT-REVIEW.md section 1. | ğŸŸ¢ | f3bde86 |
| B8 | README API table missing many implemented endpoints (`/v1/realtime`, `/api/ps`, `/v1/audio/models/*`, `/api/tts/capabilities`, etc). README env var docs missing ~15 active config knobs. See PROJECT-REVIEW.md sections 2+4+8. | ğŸŸ¢ | Replaced flat API table with categorized reference (11 sections, 55+ endpoints) with request params, response shapes, and curl examples. All env vars already documented in prior update. |
| B9 | **Streaming TTS blocks event loop** â€” `_generate()` calls `_do_synthesize()` synchronously when `stream=True` (no `run_in_executor`). Non-streaming path correctly uses executor (line 803). Heavy models (Qwen3) will stall all concurrent requests during synthesis. **File:** `src/main.py:772-779`. Fix: wrap streaming synthesis in `asyncio.get_event_loop().run_in_executor()`. | ğŸŸ¢ | already implemented |
| B10 | **TTS cache key missing model** â€” Cache key is `(text, voice, speed, format)` but omits the active model. Switching TTS backends (e.g. kokoro â†’ piper) with same voice name returns stale cached audio from wrong backend. **File:** `src/cache/tts_cache.py` + `src/main.py:797-800`. Fix: add model/backend name to cache key. | ğŸŸ¢ | 6b2aab0 |
| B11 | **`inspect.signature` called on every TTS request** â€” `_do_synthesize()` calls `inspect.signature()` at runtime for every request with `voice_design` or `reference_audio`. Slow (reflection) and fragile. **File:** `src/main.py:756-770`. Fix: use backend `capabilities` dict instead. | ğŸŸ¢ | a56d033 |
| B12 | Frontend model auto-prepare race: provider install API was fire-and-forget polling, so Generate/Transcribe could continue before install completed and fail with confusing state errors. | ğŸŸ¢ | pending |
| B40 | **`download()` calls `load()` which triggers auto-unload of existing loaded model** â€” Prefetching/downloading any model caused `_auto_unload_type` to unload already-loaded models of the same type because `download()` internally calls `load()`. Fix: add `_evict_others=False` parameter to `load()`, pass it from `download()`. | ğŸŸ¢ | pending |
| B41 | **UI poll loop never terminates on failure/revert states** â€” After a failed download, the poll loop checking model status ran indefinitely (80+ polls over 5+ minutes) because the only break condition was `state === 'loaded'/'downloaded'`. Fix: add breaks for `'available'` and `'provider_missing'` states, plus a 60-iteration (3 minute) hard timeout. | ğŸŸ¢ | pending |
| B43 | **Missing piper model variants** â€” `piper/en_US-ryan-high`, `en_US-amy-high`, `en_US-lessac-low`, `en_GB-alan-low`, `en_GB-cori-high` not in PIPER_MODELS dict. Users couldn't load/download high-quality ryan voice. Added all missing variants. | ğŸŸ¢ | <commit> |
| B44 | **Wyoming binds to 127.0.0.1 â€” Home Assistant can't connect** â€” Wyoming server default host was `127.0.0.1`, refusing external connections from HA. Changed default to `0.0.0.0` in Dockerfile ENV and docker-compose.yml. | ğŸŸ¢ | <commit> |
| B45 | **Unbaked backends show "Load to GPU" button and nuke working models** â€” pocket-tts and piper registered in the model list even when not installed. Clicking Load to GPU auto-unloaded the working model (F16), then failed. Fix: add `is_available()` classmethod to optional backends; TTSRouter skips unavailable ones; model_manager marks known models as `provider_missing` when backend not registered. | ğŸŸ¢ | <commit> |
| B46 | **Download status poll loop stuck â€” concurrent downloads never terminate** â€” Status endpoint ignored `_download_progress`; models showed `provider_installed` during download so B41 break conditions never fired. Also queued downloads had no progress entry before acquiring lock. Fixed: status endpoint overlays `_download_progress`; queued status set before lock; B41 resets poll timeout on active progress. | ğŸŸ¢ | <commit> |
| B47 | **Web UI audio streaming buffered full response before playback** â€” Generate button used `res.blob()` which collects all audio before playing. Fixed with MediaSource API + streaming fetch: audio plays as first chunks arrive. Falls back to blob for non-mp3 formats. | ğŸŸ¢ | <commit> |

## Fixes

| # | Description | Status | Commit |
|---|-------------|--------|--------|
| F1 | Speed slider 0.25 step â†’ 5% increments | ğŸŸ¢ | 75fb457 |
| F2 | Kokoro showing in STT dropdown | ğŸŸ¢ | c128533 |
| F3 | Kokoro-82M listed as STT in Models tab | ğŸŸ¢ | c128533 |
| F4 | Models show Download but provider not installed | ğŸŸ¢ | c128533 |
| F5 | Version badge showed v1.0 | ğŸŸ¢ | c128533 |
| F6 | Voice presets didn't match actual voices | ğŸŸ¢ | 75fb457 |
| F7 | *(removed â€” vosk backend removed)* | ğŸŸ¢ | â€” |
| F8 | Realtime audio buffer limit + idle timeout protections | ğŸŸ¢ | pending |
| F9 | Auth hardening (`OS_AUTH_REQUIRED`, startup warning, query-key deprecation) | ğŸŸ¢ | pending |
| F10 | WS origin allowlist + Wyoming localhost default bind | ğŸŸ¢ | pending |
| F11 | Voice clone upload size limit + TLS cert dir hardening | ğŸŸ¢ | pending |
| F12 | Docker non-root user + cache/cert path updates | ğŸŸ¢ | pending |
| F13 | Model manager concurrency locks + realtime model resolution fix | ğŸŸ¢ | pending |
| F14 | Manual model lifecycle: provider install/download/load/unload/delete with actionable errors | ğŸŸ¢ | pending |
| F15 | UX/model-flow rescue pass: auto-prepare on Generate/Transcribe, `ensureModelReady(modelId)`, capability-aware advanced controls, focused defaults (kokoro/piper + faster-whisper), and cleaner status-driven UI | ğŸŸ¢ | pending |

## Features

| # | Description | Status | Commit |
|---|-------------|--------|--------|
| T1 | TTS history â€” download + delete buttons | ğŸŸ¢ | c128533 |
| T2 | Stream toggle tooltip | ğŸŸ¢ | c128533 |
| T3 | Voice presets dropdown in Speak tab | ğŸŸ¢ | 0ea4d4c |
| T4 | Voice cloning endpoint (`/v1/audio/speech/clone`) | ğŸŸ¢ | 0ea4d4c |
| T5 | Qwen3-TTS backend | ğŸŸ¢ | 0ea4d4c |
| T6 | *(removed â€” fish-speech backend removed)* | ğŸŸ¢ | â€” |
| T7 | TTS response cache with LRU + cache bypass | ğŸŸ¢ | pending |
| T8 | STT diarization option (`diarize=true`) | ğŸŸ¢ | pending |
| T9 | STT/TTS audio pre/post processing pipeline | ğŸŸ¢ | pending |
| T10 | Python client SDK + example | ğŸŸ¢ | pending |
| T11 | Pronunciation dictionary + SSML subset | ğŸŸ¢ | pending |

---

*To add: just tell Will in Discord. He'll add it here and batch dispatch to Forge.*
| B30 | **qwen3-tts Install button resets â€” no feedback, reverts to Install** â€” Clicking Install on qwen3-tts in the Providers list shows no spinner, no progress, no error â€” button just bounces back to "Install". Root cause: B26 (missing `qwen-tts>=0.1.0` in `PROVIDER_INSTALL_SPECS["qwen3"]`) causes the pip install subprocess to fail silently. The UI now keeps an error-state retry button and shows inline error text on failure. | ğŸŸ¢ | f8a9585 |
| B29 | **Voice Effects checkboxes misaligned â€” controls appear but are non-functional** â€” Voice Effects section now uses tight inline label+checkbox controls with full clickable labels; layout no longer spreads checkbox and text apart. | ğŸŸ¢ | f8a9585 |
| B28 | **Models tab empty on load, 30s timeout before populating** â€” `/api/models` is fetched once at init; STT/TTS loaders consume cache, and non-critical startup loaders are non-blocking via settled promises. Added simple loading placeholders to STT/TTS selectors. | ğŸŸ¢ | f8a9585 |
| B27 | **Unloading model doesn't release VRAM** â€” Added `gc.collect()` + CUDA cache emptying in affected unload paths (kokoro, qwen3 backend, faster-whisper) to mirror working backends. | ğŸŸ¢ | f8a9585 |
| B26 | **Qwen3-TTS install missing `qwen-tts` package** â€” Added `qwen-tts>=0.1.0` install spec and corrected install guidance message in qwen3 backend import error. | ğŸŸ¢ | f8a9585 |
| B13 | **Speak tab model selector confusing** â€” Model dropdown shows full registry paths (`piper/en_US-ryan-medium`) mixing provider+model+voice into one field. Should be three separate dropdowns: Provider (installed TTS only) â†’ Voice (for that provider) â†’ Preset. Defaults to wrong/missing model instead of loaded model. | ğŸŸ¢ | f21169c |
| B33 | **Remove provider management UI and runtime pip install â€” bake-first architecture** | ğŸŸ¢ | d9267a3 |
| B14 | **TTS model state never reaches `downloaded`** â€” `list_all()` checks HF cache for STT models via `list_cached_models()` but always passes `is_downloaded=False` for TTS models. After provider install, kokoro/piper stays `provider_installed` forever even if weights are already cached. Fix: (1) backend â€” wire `_candidate_artifact_paths()` into `list_all()` for TTS models, set `is_downloaded=True` if any artifact path exists. (2) UX follow-up â€” explicit **Cache (prefetch)** action + clearer model-state messaging (installed vs cached vs loaded), plus bake-time provider/model controls in Docker. | ğŸŸ¢ | 6cfb90d + UX follow-up |
| B34 | **qwen3 install: transformers 4.x requires huggingface-hub<1.0, conflicts with qwen-tts 0.1.x** â€” pinned transformers>=5.0.0 (which dropped the huggingface-hub<1.0 constraint), added --upgrade to BAKED_PROVIDERS install, and added minimum version pins for accelerate, soundfile, librosa in all qwen3 specs. | ğŸŸ¢ | 2e3cdcc |
| B35 | **kokoro + qwen-tts transformers conflict** â€” qwen-tts hard-pins transformers==4.57.3; cannot be installed alongside transformers>=5.0.0 in one pip call. Fix: split into two sequential installs â€” qwen-tts first (gets 4.57.3), then kokoro separately (uses whatever is installed). Removed transformers>=5.0.0 from all qwen3 specs. | ğŸŸ¢ | 931167e |
| B36 | **torch version upgrade breaks torchaudio** â€” second pip call included bare `torch` with `--upgrade`, upgrading from CUDA-built 2.5.1+cu121 to PyPI 2.10.0; ABI mismatch breaks torchaudio. Fix: removed `torch` from second pip call entirely â€” it is already installed from CUDA index. | ğŸŸ¢ | 1d76891 |
| B37 | **qwen-tts poisons entire environment via transformers==4.57.3 hard huggingface-hub<1.0 check** â€” transformers==4.57.3 (hard-pinned by qwen-tts) raises `ImportError` at module import time if huggingface-hub>=1.0 is installed. This killed kokoro (which imports AlbertModel from transformers) and faster-whisper. Fix: (1) remove qwen3 from default BAKED_PROVIDERS (now kokoro only); (2) when qwen3 is explicitly baked, install qwen-tts with `--no-deps` then manually wire transformers>=5.0.0 + huggingface-hub>=1.0. | ğŸŸ¢ | pending |
| B38 | **Non-baked backends show generic Python ImportError instead of clean "not installed" message** â€” piper not in BAKED_PROVIDERS returns `No module named 'piper'` (raw 500) instead of a user-friendly error. The provider_missing check should catch this and return a clean 400 with rebuild instructions. | ğŸŸ¢ | d3c58d6 |
| F16 | **Allow loading multiple STT models simultaneously â€” should enforce 1 STT + 1 TTS max** â€” Currently `OS_MAX_LOADED_MODELS=0` (unlimited). User expects single-model-per-type enforcement: loading a second STT should auto-unload the first. Fix: add per-type limits (STT max=1, TTS max=1) enforced at load time, or use `OS_MAX_LOADED_MODELS=2` as a stopgap. | ğŸŸ¢ | 8a6ba03 |
| B39 | **"Cache" and "Load" button labels are confusing** â€” Cache = download weights to disk; Load = move weights into GPU VRAM. Users click Cache, skip Load, then get 30s generation because the model loads inline. Fix: rename to "Download" + "Load to GPU", add tooltip, auto-load on first Generate if only cached. | ğŸŸ¢ | 82594cc |
| B40 | **Docker image layer bloat from package reinstalls across layers** â€” bake script installs unpinned transitive deps (numpy, onnxruntime, huggingface-hub, scipy) then requirements.lock reinstalls pinned versions in a later layer; Docker stores both versions (~200MB dead bytes). Fix: removed onnxruntime/huggingface-hub from qwen3 explicit deps, added version alignment step at end of bake script to pre-pin packages to match requirements.lock. | ğŸŸ¢ | 10b25c8 |
| B39 | **"Cache" and "Load" button labels are confusing** â€” Users click Cache, expect audio to work fast, then get 30s wait because Cache â‰  ready-to-run. Cache = download to disk; Load = move to GPU VRAM. Labels should read "Download" and "Load to GPU" (or at minimum, a tooltip explaining the difference). Auto-load on first Generate if model is only cached would also help. | ğŸŸ¢ | 82594cc |
| F17 | **Piper not in default BAKED_PROVIDERS** â€” piper backend is fully implemented but `piper-tts` package is not installed in the default image. Added `piper` to default `BAKED_PROVIDERS` in Dockerfile + docker-compose.yml. | ğŸŸ¢ | 82594cc |
| F18 | **Wyoming protocol disabled by default** â€” Wyoming server is fully implemented but `OS_WYOMING_ENABLED` defaulted to `false`. Flipped to `true` in Dockerfile ENV + docker-compose.yml so Home Assistant can connect without manual env override. | ğŸŸ¢ | 82594cc |
| F19 | Full Piper English catalog expanded in backend + registry (en_US + en_GB low/medium/high variants) | ğŸŸ¢ | <commit> |
| F20 | Added distil-whisper model metadata entries (small.en, medium.en, large-v3) | ğŸŸ¢ | <commit> |
| F21 | Added m4a format support to TTS API + ffmpeg pipeline/content-type map | ğŸŸ¢ | <commit> |
| F22 | Added Kokoro CUDA warmup after pipeline init to eliminate first-request kernel compile stall | ğŸŸ¢ | <commit> |
| F23 | Enabled BuildKit pip cache mounts in Dockerfile and Dockerfile.cpu (`# syntax=` + `--mount=type=cache`) | ğŸŸ¢ | <commit> |
| F24 | Reworked streaming TTS into true queue-based async streaming (no full-buffer `list()` call) | ğŸŸ¢ | <commit> |
| F25 | Added HF token passthrough (`HF_TOKEN`, `HUGGINGFACE_HUB_TOKEN`) in Docker + compose, and wired startup preloads after Wyoming start | ğŸŸ¢ | <commit> |
| F26 | UI now renders `provider_missing`/`provider_available=false` as grayed-out â€œNot installedâ€ rows with blocked actions | ğŸŸ¢ | <commit> |
