# Open Speech â€” Roadmap

Current version: **v0.5.1**  
Next target: **v0.6.0 "Studio"**

---

## âœ… Phases Complete

### Phase 2 â€” Multi-Model + Streaming
- Multiple simultaneous TTS/STT model support
- Streaming STT via WebSocket (`/v1/audio/stream`)
- File upload transcription
- Response format selection (text, json, srt, vtt)
- Faster-Whisper, Moonshine, Vosk STT backends

### Phase 3 â€” Unified Model Architecture
- Single Docker image (GPU + CPU Dockerfiles)
- Unified `ModelManager` â€” download, load, unload, status
- Provider install system â€” pip install at runtime from UI
- Model registry (`src/model_registry.py`) â€” curated model catalog
- Config-driven via environment variables

### Phase 4 â€” Advanced TTS
- **Kokoro** â€” 52 voices, voice blending, high quality
- **Piper** â€” lightweight, fast, per-model voices
- **Qwen3-TTS** â€” voice design + zero-shot cloning
- **Fish Speech** â€” zero-shot voice cloning
- **F5-TTS** â€” flow matching voice cloning
- **XTTS v2** â€” multilingual cloning (16 languages)
- Extended TTS API: `voice_design`, `reference_audio`, `/v1/audio/speech/clone`
- Voice Reference Library â€” upload named voices, reuse by name

### Phase 5 â€” Voice Assistant Integration
- **Wyoming protocol** server (`src/wyoming/`) â€” Home Assistant drop-in
- **Silero VAD** (`src/vad/silero.py`) â€” voice activity detection
- **Real-time API** (`src/realtime/`) â€” OpenAI Realtime protocol compatible
- **Live mic streaming** â€” browser WebSocket â†’ VAD â†’ STT â†’ transcript
- Anti-aliasing resampler (48kHzâ†’16kHz, scipy `resample_poly`)

### Phase 6 â€” Production Hardening
- **TTS response cache** (`src/cache/tts_cache.py`) â€” SHA256-keyed, LRU eviction
- **Speaker diarization** (`src/diarization/`) â€” pyannote.audio, optional dep
- **Audio preprocessing** â€” noise reduction, gain normalization
- **Audio postprocessing** â€” silence trim, output normalization
- **Python client SDK** (`src/client/`) â€” sync/async transcribe + speak
- **Pronunciation dictionary** (`src/pronunciation/`) â€” JSON/YAML substitutions, SSML subset

### Phase 8a â€” Voice Profiles *(shipped in v0.5.1)*
- Named persistent voice profiles (`src/profiles.py`)
- Full CRUD API: `POST/GET/PUT/DELETE /api/profiles`
- Default profile support
- Profile selector in Speak tab â†’ one-click restore all settings
- Persisted to `studio.db` (SQLite, WAL mode)

### Phase 8b â€” Generation History *(shipped in v0.5.1)*
- TTS + STT history log (`src/history.py`)
- Auto-logged after every successful generation/transcription
- Streamed requests: metadata-only (no audio file)
- API: `GET /api/history`, `DELETE /api/history/{id}`, `DELETE /api/history`
- History tab in web UI â€” paginated, re-generate, delete
- Configurable retention: `OS_HISTORY_MAX_ENTRIES`, `OS_HISTORY_MAX_MB`

### Phase 8e â€” Multi-Track Composer *(shipped in v0.5.1)*
- Track mixer manager (`src/composer.py`) with per-track offset/volume/mute/solo/effects
- Composer APIs: `POST /api/composer/render`, `GET /api/composer/renders`, `GET /api/composer/render/{id}/audio`, `DELETE /api/composer/render/{id}`
- Studio tab Composer card with track rows, render playback, and history
- Secure source-path validation (data roots only) + persisted compositions in `studio.db`

---

## ðŸ”§ Current Web UI (v0.5.1)

Full 3-tab redesign (ground-up rewrite, 2026-02-20):

| Tab | Status |
|-----|--------|
| **Transcribe** | âœ… File upload + live mic, VAD indicator, partial + final results |
| **Speak** | âœ… Provider â†’ Model â†’ Voice â†’ Preset cascade, auto-load flow, Generate state machine |
| **Models** | âœ… Loaded Models, STT/TTS columns (no cross-contamination), Providers section with install/uninstall |
| **History** | âœ… Paginated TTS+STT log, re-generate, delete, clear all |
| **Settings** | âœ… Profile CRUD, history settings |

---

## ðŸš§ In Progress / Upcoming

### Bug Fixes (prioritized)
| ID | Issue | Priority |
|----|-------|----------|
| B6 | Provider install (`pip`) writes to wrong path in Docker â€” Install Provider button broken | ðŸ”´ Critical |
| B9 | Streaming TTS runs synchronously â€” blocks event loop for heavy models | ðŸ”´ Critical |
| B7 | Inconsistent error envelopes (`{"detail":...}` vs `{"error":...}`) | ðŸŸ  High |
| B11 | `inspect.signature()` called on every TTS request â€” use capabilities dict instead | ðŸŸ  High |
| B10 | TTS cache key missing model â€” wrong cached audio after backend switch | ðŸŸ¡ Medium |
| B8 | README API table still missing some endpoints | ðŸŸ¡ Medium |

### Phase 8c â€” Conversation Mode
- Multi-turn conversation builder in Studio tab
- Turn list: speaker, profile, text â†’ sequential render
- Export as single WAV/MP3 or per-turn ZIP
- REST API: `POST/GET/DELETE /api/conversations`, `POST /api/conversations/{id}/render`

### Phase 8d â€” Voice Effects
- Effects chain (`src/effects/chain.py`) â€” scipy-based
- Effects: normalize, pitch shift, room reverb, podcast EQ, robot
- Per-request `effects` parameter on `/v1/audio/speech`
- Effects panel in Speak tab (collapsible, capability-gated)

### Phase 7b-7d â€” Qwen3 Advanced *(deferred)*
- Voice design â†’ clone workflow
- Native streaming (sub-100ms first chunk)
- Batch inference + vLLM backend

---

## Not Planned
- LLM conversation / function calling (bring your own brain)
- Multi-language UI (English only)
- CI/CD pipelines
- Cloud provider integrations

---

## Version History

| Version | Highlights |
|---------|-----------|
| v0.5.1 | XTTS v2, Voice Library, Phase 8a+8b (Profiles+History), UI rewrite, Models tab redesign, Speak tab Provider/Model/Voice cascade |
| v0.5.0 | Phase 6 production hardening (cache, diarization, audio processing, client SDK) |
| v0.4.x | Phase 5: Wyoming, VAD, Realtime API, live mic streaming |
| v0.3.x | Phase 4: Advanced TTS backends (Qwen3, Fish, F5, XTTS) |
| v0.2.x | Phase 3: Unified Docker image, ModelManager, provider install |
| v0.1.x | Phase 2: Multi-model, streaming STT, file upload |
